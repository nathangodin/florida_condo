{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e010473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosswalk saved to: C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\\sirs_assoc_crosswalk_by_zip_fuzzy90.csv\n",
      "Updated master saved to: C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\\master_dataset_unit_crossection_with_SIRS_self_report.dta\n"
     ]
    }
   ],
   "source": [
    "# --- setup ---\n",
    "import os, re, glob, pathlib\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Paths (edit if needed)\n",
    "stata_path = r\"C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\\master_dataset_unit_crossection.dta\"\n",
    "excel_path = r\"C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\Structural Integrity Reserve Study (SIRS) Reporting(DAwQFJ).xlsx\"\n",
    "\n",
    "excel_dir = r\"C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\"\n",
    "\n",
    "# --- 1) Load master .dta ---\n",
    "master = pd.read_stata(stata_path, convert_categoricals=False)\n",
    "\n",
    "# ensure string types we’ll use\n",
    "for c in [\"assoc_name_final\",\"building_address_attom\",\"zip5_attom\"]:\n",
    "    if c in master.columns:\n",
    "        master[c] = master[c].astype(str).str.strip()\n",
    "    else:\n",
    "        raise KeyError(f\"Expected column '{c}' not found in master dataset.\")\n",
    "\n",
    "# --- 2) Drop rows where assoc_name_final == building_address_attom ---\n",
    "master2 = master.loc[master[\"assoc_name_final\"] != master[\"building_address_attom\"]].copy()\n",
    "\n",
    "# --- 3) Create assoc_name by removing trailing ' ZIP5' (a space + 5 digits) from assoc_name_final ---\n",
    "master2[\"assoc_name\"] = master2[\"assoc_name_final\"].str.replace(r\"\\s\\d{5}$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# --- 4) Keep only assoc_name, assoc_name_final, zip5_attom; drop duplicates on (assoc_name, zip5_attom) ---\n",
    "m_small = master2[[\"assoc_name\",\"assoc_name_final\",\"zip5_attom\"]].dropna(subset=[\"assoc_name\",\"zip5_attom\"]).copy()\n",
    "m_small = m_small.drop_duplicates(subset=[\"assoc_name\",\"zip5_attom\"])\n",
    "\n",
    "# --- 5) Load SIRS Excel, keep needed cols, take first 5 chars of Zip, drop duplicates ---\n",
    "# If the Excel file has multiple sheets and the data is on the first, this works;\n",
    "# otherwise pass sheet_name=\"YourSheet\"\n",
    "sirs_raw = pd.read_excel(excel_path, dtype=str)\n",
    "needed = {\"Project Name\":\"project_name\", \"Association Name\":\"association_name\", \"Zip\":\"zip\"}\n",
    "missing = [c for c in needed if c not in sirs_raw.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing expected Excel columns: {missing}\")\n",
    "\n",
    "sirs = sirs_raw.rename(columns=needed)[[\"project_name\",\"association_name\",\"zip\"]].copy()\n",
    "sirs[\"zip5\"] = sirs[\"zip\"].astype(str).str.strip().str[:5]\n",
    "sirs = sirs.drop(columns=[\"zip\"]).dropna(subset=[\"zip5\"])\n",
    "sirs = sirs.drop_duplicates(subset=[\"project_name\",\"association_name\",\"zip5\"]).reset_index(drop=True)\n",
    "\n",
    "# Duplicate the two SIRS name columns into a single long “name” field so either can match\n",
    "sirs_long = pd.DataFrame({\n",
    "    \"sirs_name_raw\": pd.concat([sirs[\"project_name\"], sirs[\"association_name\"]], ignore_index=True),\n",
    "    \"zip5\":          pd.concat([sirs[\"zip5\"],         sirs[\"zip5\"]],          ignore_index=True),\n",
    "    \"sirs_source\":   [\"PROJECT_NAME\"]*len(sirs) + [\"ASSOCIATION_NAME\"]*len(sirs)\n",
    "}).dropna(subset=[\"sirs_name_raw\",\"zip5\"]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# --- 6) Standardization function (uppercase, suffix INC removal, standardize tokens, rm punctuation) ---\n",
    "INC_SUFFIX_RE = re.compile(r\"(,?\\s+INC\\.?)\\s*$\")\n",
    "def std_name(x: str) -> str:\n",
    "    if pd.isna(x): return x\n",
    "    s = str(x).upper().strip()\n",
    "\n",
    "    # remove trailing INC variants at end only\n",
    "    s = INC_SUFFIX_RE.sub(\"\", s)\n",
    "\n",
    "    # standardize tokens\n",
    "    # typos to CONDO\n",
    "    s = re.sub(r\"\\bCONDOMIUM\\b|\\bCONDMINIUM\\b|\\bCONDOMINIUM\\b\", \"CONDO\", s)\n",
    "    # association family -> ASSOC\n",
    "    s = re.sub(r\"\\bASSOCIATION\\b|\\bASSN\\.?\\b|\\bASSOC\\.?\\b\", \"ASSOC\", s)\n",
    "    # apartments -> APTS\n",
    "    s = re.sub(r\"\\bAPARTMENTS\\b\", \"APTS\", s)\n",
    "\n",
    "    # remove commas and periods\n",
    "    s = s.replace(\",\", \"\").replace(\".\", \"\")\n",
    "\n",
    "    # collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "m_small[\"assoc_name_std\"] = m_small[\"assoc_name\"].map(std_name)\n",
    "sirs_long[\"sirs_name_std\"] = sirs_long[\"sirs_name_raw\"].map(std_name)\n",
    "\n",
    "# also align ZIPs to strings & consistent names\n",
    "m_small = m_small.rename(columns={\"zip5_attom\":\"zip5\"})\n",
    "m_small[\"zip5\"] = m_small[\"zip5\"].astype(str).str.strip().str[:5]\n",
    "\n",
    "# --- 7) Fuzzy match within ZIP (>=90), using RapidFuzz token_set_ratio ---\n",
    "def match_within_zip(zip_code, sirs_block, master_block):\n",
    "    # build choices dict {name_std: (assoc_name_std, assoc_name, assoc_name_final)}\n",
    "    choices = dict()\n",
    "    for _, r in master_block.iterrows():\n",
    "        choices[r[\"assoc_name_std\"]] = (r[\"assoc_name_std\"], r[\"assoc_name\"], r[\"assoc_name_final\"])\n",
    "\n",
    "    out = []\n",
    "    for _, r in sirs_block.iterrows():\n",
    "        q = r[\"sirs_name_std\"]\n",
    "        if not q or not len(choices):\n",
    "            continue\n",
    "        match = process.extractOne(\n",
    "            q,\n",
    "            choices.keys(),\n",
    "            scorer=fuzz.token_set_ratio,\n",
    "            score_cutoff=90  # 90% threshold\n",
    "        )\n",
    "        if match:\n",
    "            key, score, _ = match\n",
    "            assoc_name_std, assoc_name, assoc_name_final = choices[key]\n",
    "            out.append({\n",
    "                \"zip5\": zip_code,\n",
    "                \"sirs_name_raw\": r[\"sirs_name_raw\"],\n",
    "                \"sirs_name_std\": q,\n",
    "                \"sirs_source\": r[\"sirs_source\"],\n",
    "                \"assoc_name_std\": assoc_name_std,\n",
    "                \"assoc_name\": assoc_name,\n",
    "                \"assoc_name_final\": assoc_name_final,\n",
    "                \"match_score\": score\n",
    "            })\n",
    "    return out\n",
    "\n",
    "matches = []\n",
    "for z, sblk in sirs_long.groupby(\"zip5\", sort=False):\n",
    "    mblk = m_small.loc[m_small[\"zip5\"]==z]\n",
    "    if len(mblk)==0: \n",
    "        continue\n",
    "    matches.extend(match_within_zip(z, sblk, mblk))\n",
    "\n",
    "crosswalk = pd.DataFrame(matches).drop_duplicates()\n",
    "\n",
    "# --- 8) Save crosswalk in the same folder ---\n",
    "crosswalk_path = os.path.join(excel_dir, \"sirs_assoc_crosswalk_by_zip_fuzzy90.csv\")\n",
    "crosswalk.to_csv(crosswalk_path, index=False)\n",
    "\n",
    "# --- 9) Add SIRS_self_report to the ORIGINAL master without altering anything else ---\n",
    "# A pair is “covered” if its (assoc_name_final, zip5_attom) appears in matched results\n",
    "matched_keys = set(\n",
    "    crosswalk[[\"assoc_name_final\",\"zip5\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "# create the flag without touching other columns\n",
    "master_out = master.copy()\n",
    "master_out[\"zip5_attom\"] = master_out[\"zip5_attom\"].astype(str).str.strip().str[:5]\n",
    "master_out[\"SIRS_self_report\"] = master_out[[\"assoc_name_final\",\"zip5_attom\"]].apply(\n",
    "    lambda r: 1 if (str(r[\"assoc_name_final\"]).strip(), str(r[\"zip5_attom\"]).strip()) in matched_keys else 0,\n",
    "    axis=1\n",
    ").astype(\"int8\")\n",
    "\n",
    "# --- 10) Save master with new flag (write a new file to avoid overwriting) ---\n",
    "out_path = os.path.join(\n",
    "    os.path.dirname(stata_path),\n",
    "    pathlib.Path(stata_path).stem + \"_with_SIRS_self_report.dta\"\n",
    ")\n",
    "master_out.to_stata(out_path, write_index=False)\n",
    "\n",
    "print(\"Crosswalk saved to:\", crosswalk_path)\n",
    "print(\"Updated master saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaab3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          county  total_3plus_assocs  sirs_report_count  frac_sirs  \\\n",
      "0     MIAMI-DADE                1821                492   0.270181   \n",
      "1        BROWARD                1533                467   0.304631   \n",
      "2       PINELLAS                 867                217   0.250288   \n",
      "3     PALM BEACH                 782                232   0.296675   \n",
      "4            LEE                 390                 89   0.228205   \n",
      "5       SARASOTA                 340                 87   0.255882   \n",
      "6        COLLIER                 334                 81   0.242515   \n",
      "7        VOLUSIA                 244                 79   0.323770   \n",
      "8        BREVARD                 190                 54   0.284211   \n",
      "9         ORANGE                 185                 20   0.108108   \n",
      "10       MANATEE                 181                 46   0.254144   \n",
      "11  HILLSBOROUGH                 171                 27   0.157895   \n",
      "12      SEMINOLE                 163                  8   0.049080   \n",
      "13     ST. JOHNS                 143                 17   0.118881   \n",
      "14      OKALOOSA                 143                 62   0.433566   \n",
      "15     CHARLOTTE                 143                 23   0.160839   \n",
      "16        WALTON                 123                 20   0.162602   \n",
      "17         DUVAL                 119                 45   0.378151   \n",
      "18       OSCEOLA                 108                  8   0.074074   \n",
      "19  INDIAN RIVER                 105                 45   0.428571   \n",
      "20           BAY                  96                 29   0.302083   \n",
      "21     ST. LUCIE                  96                 25   0.260417   \n",
      "22      ESCAMBIA                  89                 33   0.370787   \n",
      "23        MONROE                  55                 21   0.381818   \n",
      "24        MARTIN                  49                 16   0.326531   \n",
      "25       FLAGLER                  45                  9   0.200000   \n",
      "26          POLK                  37                  1   0.027027   \n",
      "27         PASCO                  28                  2   0.071429   \n",
      "28       ALACHUA                  27                  9   0.333333   \n",
      "29    SANTA ROSA                  15                  5   0.333333   \n",
      "30          LEON                  13                  4   0.307692   \n",
      "31        NASSAU                  11                  5   0.454545   \n",
      "32          LAKE                   7                  1   0.142857   \n",
      "33          CLAY                   7                  1   0.142857   \n",
      "34     HIGHLANDS                   4                  1   0.250000   \n",
      "35        CITRUS                   4                  0   0.000000   \n",
      "36        MARION                   3                  0   0.000000   \n",
      "37          LEVY                   1                  0   0.000000   \n",
      "\n",
      "    frac_sirs_pct  \n",
      "0            27.0  \n",
      "1            30.5  \n",
      "2            25.0  \n",
      "3            29.7  \n",
      "4            22.8  \n",
      "5            25.6  \n",
      "6            24.3  \n",
      "7            32.4  \n",
      "8            28.4  \n",
      "9            10.8  \n",
      "10           25.4  \n",
      "11           15.8  \n",
      "12            4.9  \n",
      "13           11.9  \n",
      "14           43.4  \n",
      "15           16.1  \n",
      "16           16.3  \n",
      "17           37.8  \n",
      "18            7.4  \n",
      "19           42.9  \n",
      "20           30.2  \n",
      "21           26.0  \n",
      "22           37.1  \n",
      "23           38.2  \n",
      "24           32.7  \n",
      "25           20.0  \n",
      "26            2.7  \n",
      "27            7.1  \n",
      "28           33.3  \n",
      "29           33.3  \n",
      "30           30.8  \n",
      "31           45.5  \n",
      "32           14.3  \n",
      "33           14.3  \n",
      "34           25.0  \n",
      "35            0.0  \n",
      "36            0.0  \n",
      "37            0.0  \n",
      "\n",
      "Top 10 by total 3+ story associations:\n",
      "\n",
      "       county  total_3plus_assocs  sirs_report_count  frac_sirs  frac_sirs_pct\n",
      "0  MIAMI-DADE                1821                492   0.270181           27.0\n",
      "1     BROWARD                1533                467   0.304631           30.5\n",
      "2    PINELLAS                 867                217   0.250288           25.0\n",
      "3  PALM BEACH                 782                232   0.296675           29.7\n",
      "4         LEE                 390                 89   0.228205           22.8\n",
      "5    SARASOTA                 340                 87   0.255882           25.6\n",
      "6     COLLIER                 334                 81   0.242515           24.3\n",
      "7     VOLUSIA                 244                 79   0.323770           32.4\n",
      "8     BREVARD                 190                 54   0.284211           28.4\n",
      "9      ORANGE                 185                 20   0.108108           10.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---- paths ----\n",
    "unit_path = r\"C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\\master_dataset_unit_crossection_with_SIRS_self_report.dta\"\n",
    "\n",
    "# ---- load + keep needed cols ----\n",
    "use_cols = [\"assoc_name_final\", \"SIRS_self_report\", \"mm_fips_county_name_attom\", \"treated_assoc\"]\n",
    "df = pd.read_stata(unit_path, columns=use_cols, convert_categoricals=False)\n",
    "\n",
    "# ensure expected dtypes\n",
    "df[\"assoc_name_final\"] = df[\"assoc_name_final\"].astype(str).str.strip()\n",
    "df[\"mm_fips_county_name_attom\"] = df[\"mm_fips_county_name_attom\"].astype(str).str.strip()\n",
    "df[\"SIRS_self_report\"] = pd.to_numeric(df[\"SIRS_self_report\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"treated_assoc\"] = pd.to_numeric(df[\"treated_assoc\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# ---- filter to treated (3+ stories) and dedupe by association name ----\n",
    "treated = (\n",
    "    df.loc[df[\"treated_assoc\"] == 1, [\"assoc_name_final\", \"SIRS_self_report\", \"mm_fips_county_name_attom\"]]\n",
    "      .drop_duplicates(subset=[\"assoc_name_final\"])\n",
    "      .rename(columns={\"mm_fips_county_name_attom\": \"county\"})\n",
    ")\n",
    "\n",
    "# ---- by-county counts and fractions ----\n",
    "by_cty = (\n",
    "    treated.groupby(\"county\", dropna=False)\n",
    "           .agg(total_3plus_assocs=(\"assoc_name_final\", \"count\"),\n",
    "                sirs_report_count=(\"SIRS_self_report\", \"sum\"))\n",
    "           .reset_index()\n",
    ")\n",
    "by_cty[\"frac_sirs\"] = by_cty[\"sirs_report_count\"] / by_cty[\"total_3plus_assocs\"]\n",
    "\n",
    "# ---- overall row ----\n",
    "overall = pd.DataFrame({\n",
    "    \"county\": [\"OVERALL\"],\n",
    "    \"total_3plus_assocs\": [len(treated)],\n",
    "    \"sirs_report_count\": [treated[\"SIRS_self_report\"].sum()]\n",
    "})\n",
    "overall[\"frac_sirs\"] = overall[\"sirs_report_count\"] / overall[\"total_3plus_assocs\"]\n",
    "\n",
    "# ---- final table (by county + overall), sorted by fraction desc ----\n",
    "table = pd.concat([by_cty, overall], ignore_index=True)\n",
    "table = table.sort_values(\n",
    "    by=[\"county\"], key=lambda s: s.where(s.eq(\"OVERALL\"), \"A\"+s)  # keep OVERALL at bottom\n",
    ")\n",
    "\n",
    "# pretty percentage column if you want to display/export\n",
    "table_display = table.copy()\n",
    "table_display[\"frac_sirs_pct\"] = (table_display[\"frac_sirs\"] * 100).round(1)\n",
    "\n",
    "# --- sort by total_3plus_assocs (largest -> smallest) and print ---\n",
    "sorted_table = (\n",
    "    table_display.loc[table_display[\"county\"] != \"OVERALL\"]  # drop overall for sorting\n",
    "                 .sort_values(\"total_3plus_assocs\", ascending=False)\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "print(sorted_table)  # print full sorted table if you want\n",
    "print(\"\\nTop 10 by total 3+ story associations:\\n\")\n",
    "print(sorted_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76389db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table saved to: C:\\Users\\ngodin\\Dropbox\\RESEARCH\\active_projects\\florida_condo\\final_datasets\\master_datasets\\top10_sirs_by_county.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngodin\\AppData\\Local\\Temp\\ipykernel_29928\\3144523900.py:18: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  top10.to_latex(\n"
     ]
    }
   ],
   "source": [
    "# --- take top 10 and build LaTeX table ---\n",
    "top10 = sorted_table.head(10).copy()\n",
    "\n",
    "# keep county, total, and the percent column (not the raw fraction)\n",
    "top10 = top10[[\"county\", \"total_3plus_assocs\", \"frac_sirs_pct\"]].rename(\n",
    "    columns={\n",
    "        \"county\": \"County\",\n",
    "        \"total_3plus_assocs\": \"3+ Story Associations\",\n",
    "        \"frac_sirs_pct\": \"Self-reported SIRS (%)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# format percent with a trailing % for LaTeX\n",
    "top10[\"Self-reported SIRS (%)\"] = top10[\"Self-reported SIRS (%)\"].map(lambda x: f\"{x:.1f}\\\\%\")\n",
    "\n",
    "# export to LaTeX in the same folder as the unit file\n",
    "latex_out = os.path.join(os.path.dirname(unit_path), \"top10_sirs_by_county.tex\")\n",
    "top10.to_latex(\n",
    "    latex_out,\n",
    "    index=False,\n",
    "    escape=False,                 # allow the % signs we added\n",
    "    column_format=\"lrr\",          # left, right, right\n",
    "    caption=\"Top 10 Florida counties by number of 3+ story condo associations and their self-reported SIRS rates.\",\n",
    "    label=\"tab:top10_sirs_by_county\"\n",
    ")\n",
    "\n",
    "print(\"LaTeX table saved to:\", latex_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
